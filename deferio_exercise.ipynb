{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18814bac-cbbf-4b88-9b49-a520c9865a61",
   "metadata": {},
   "source": [
    "### Setup methods and data utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5060ec-d195-4a99-9f2c-8e46784649b3",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "    - This assumes you already have jupyter-notebooks installed in your python environment\n",
    "    - Cells 1-4 can be run to accomplish the following:\n",
    "        - import packages\n",
    "        - setup variables for the exercise\n",
    "        - establish utility methods\n",
    "        - setup db and process files\n",
    "    - The remaining cells will perform the analyses and output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db7d97-eede-44de-af7f-20fcc5bf0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "import json\n",
    "import sqlite3\n",
    "import datetime\n",
    "import typing as t\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa28e9e-2b0e-4869-87a6-cad0792150cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = t.TypeVar(\"T\")\n",
    "pharmacy_dir = Path.cwd().joinpath('pharmacy_claims')\n",
    "file_type = ['enrollment', 'pharmacy_claims', 'analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeec55f-7514-41bb-806d-506988577306",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {\n",
    "    \"enrollment\": {\n",
    "        \"fields\": [\n",
    "            {\"name\": \"birth_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"card_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"enrollment_end_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"enrollment_start_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"first_name\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"gender\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"last_name\", \"type\": \"text\", \"format\": \"\"}\n",
    "        ]\n",
    "    },\n",
    "    \"pharmacy_claims\": {\n",
    "        \"fields\": [\n",
    "            {\"name\": \"allowed_amount\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"card_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"claim_line_number\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"claim_status\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"days_supply\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"fill_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"maintenance_drug_flag\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"medication_name\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"ndc_11\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"paid_date\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"pharmacy_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"pharmacy_name\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"pharmacy_npi\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"pharmacy_tax_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"prescriber_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"prescriber_npi\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"quantity_dispensed\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"refill_number\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"retail_mail_flag\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"run_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"rxtype\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"specialty_drug_flag\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"strength_units\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"strength_value\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"uploadDate\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"claim_number\", \"type\": \"text\", \"format\": \"\"}\n",
    "        ]\n",
    "    },\n",
    "    \"analysis\": {\n",
    "        \"fields\": [\n",
    "            {\"name\": \"card_id\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"claim_number\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"fill_date\", \"type\": \"date\", \"format\": \"%Y-%m-%d\"},\n",
    "            {\"name\": \"ndc_11\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"claim_status\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"days_supply\", \"type\": \"text\", \"format\": \"\"},\n",
    "            {\"name\": \"allowed_amount\", \"type\": \"text\", \"format\": \"\"}\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcb98d-a90d-4657-87b2-00eeb1ae4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_from_file(json_file_path: Path):\n",
    "    \"\"\"load json file and parse as dict\"\"\"\n",
    "    with open(json_file_path) as fhandle:\n",
    "        filestr = fhandle.read()\n",
    "    return json.loads(filestr)\n",
    "\n",
    "class CSVDialect(csv.Dialect):\n",
    "    \"\"\"Dialect for file ingestion\"\"\"\n",
    "    \n",
    "    delimiter = \",\"\n",
    "    doublequote = True\n",
    "    escapechar = \"\\\\\"\n",
    "    quotechar = '\"'\n",
    "    strict = True\n",
    "    lineterminator = \"\\r\\n\"\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "    \n",
    "def convert_ndc(ndc11: str):\n",
    "    \"\"\"Convert between ndc formats 11 > 9\"\"\"\n",
    "    ndc11_fmt = f'{ndc11[:5]}-{ndc11[5:]}'\n",
    "    return ndc11_fmt[:-2]\n",
    "    \n",
    "def generate_ddl_scripts(schemas: dict):\n",
    "    \"\"\"creates a ddl file from the schema json\"\"\"\n",
    "    \n",
    "    ddl_list = []\n",
    "    for schema_type in file_type: \n",
    "        schema = schema_dict.get(schema_type)\n",
    "    \n",
    "        expected_headers = [(field[\"name\"].lower(), field[\"type\"]) for field in schema[\"fields\"]]\n",
    "        file_ddl = f\"\"\"create table if not exists \"{schema_type}\" (\n",
    "            {', '.join(f'\"{h[0]}\" {h[1]}' for h in expected_headers)}\n",
    "        )\"\"\";\n",
    "        ddl_list.append(file_ddl)\n",
    "    return ddl_list\n",
    "              \n",
    "def establish_sqlite_db(\n",
    "    path: Path = None, \n",
    "    schemas: dict = schema_dict) -> sqlite3.Connection:\n",
    "    \"\"\"creates a sqlite db with tables and returns a connection object\"\"\"\n",
    "    \n",
    "    if path != \"\" and Path(path).exists():\n",
    "        print(f\"Database {path!s} already exists. Deleting..\")\n",
    "        Path(path).unlink()\n",
    "    \n",
    "    conn = sqlite3.connect(path, check_same_thread=False)\n",
    "    print(f\"DB setup at {path}\")\n",
    "    \n",
    "    # generate schema ddl and add tables\n",
    "    ddl_list = generate_ddl_scripts(schemas)\n",
    "    cur = conn.cursor()\n",
    "    for ddl in ddl_list:\n",
    "        cur.execute(ddl)\n",
    "    cur.close()\n",
    "    return conn\n",
    "\n",
    "def get_line_count(path: Path) -> int:\n",
    "    \"\"\"create buffered read generator to determin line count of file\"\"\"\n",
    "    def _make_gen(reader):\n",
    "        while True:\n",
    "            b = reader(2**16)\n",
    "            if not b:\n",
    "                break\n",
    "            yield b\n",
    "    with open(path, \"rb\") as f:\n",
    "        count = sum(buf.count(b\"\\n\") for buf in _make_gen(f.raw.read))\n",
    "    return int(count)\n",
    "\n",
    "def csv_to_ordered_dict(csv_path: Path, fields: list):\n",
    "    retval, quarantine = [], []\n",
    "    with open(csv_path, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile, dialect=CSVDialect)\n",
    "        rownum = 1\n",
    "        for row in reader:\n",
    "            if len(row.keys()) != len(fields):\n",
    "                print(f'Row {rownum}: Wrong number of fields found')\n",
    "                quarantine.append(row)\n",
    "            else:\n",
    "                retval.append(row)\n",
    "            rownum += 1\n",
    "        return retval, quarantine\n",
    "\n",
    "def process_data_file(data_path: Path, schema: dict):\n",
    "    \"\"\"process and clean data files; isolate problematic records\"\"\"\n",
    "    \n",
    "    fields = schema[\"fields\"]\n",
    "    fieldnames = [f[\"name\"] for f in fields]\n",
    "    data, quarantine = csv_to_ordered_dict(data_path, fieldnames)\n",
    "    \n",
    "    rows = []\n",
    "    for record in data:\n",
    "        base_record = OrderedDict([(field[\"name\"], \"\") for field in fields])\n",
    "        for field in fields:\n",
    "            value = record[field[\"name\"]].strip()\n",
    "            newvalue = None\n",
    "            if field[\"type\"] == 'date':\n",
    "                if value != \"\":\n",
    "                    try:\n",
    "                        datetime.datetime.strptime(value, field[\"format\"])\n",
    "                    except ValueError:\n",
    "                        newvalue = parse(value)\n",
    "            if newvalue:\n",
    "                base_record[field[\"name\"]] = newvalue\n",
    "            else:\n",
    "                base_record[field[\"name\"]] = value\n",
    "        rows.append(base_record)\n",
    "    return rows, quarantine\n",
    "\n",
    "\n",
    "def load_data_to_db(\n",
    "    data: t.Iterable[T], \n",
    "    schema_type:str, \n",
    "    schema: dict, \n",
    "    db_path: Path,\n",
    "    conn: sqlite3.Connection):\n",
    "    \"\"\"load processed files into db\"\"\"\n",
    "    \n",
    "    fields = schema[\"fields\"]\n",
    "    ordered_fields = \", \".join(f'\"{f[\"name\"]}\"' for f in fields)\n",
    "    qmarks = \",\".join([\"?\"] * len(fields))\n",
    "    insert_stmt = f'insert into \"{schema_type}\" ({ordered_fields}) values ({qmarks});'\n",
    "    \n",
    "    data_gen = (rec for rec in data)\n",
    "    cur = conn.cursor()\n",
    "    while True:\n",
    "        try:\n",
    "            record_dict = next(data_gen)\n",
    "            record = [v for k,v in record_dict.items()]\n",
    "        except StopIteration:\n",
    "            print(f\"StopIteration Encountered. Ending db load for {schema_type}.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            cur.execute(insert_stmt, [*record])\n",
    "        except (sqlite3.Error, sqlite3.OperationalError, sqlite3.IntegrityError,) as sql_er:\n",
    "            error_args = \" \".join(sql_er.args)\n",
    "            print(f\"SQLiiteError: {sql_er.__class__} - {error_args}\")\n",
    "    conn.commit()\n",
    "    return\n",
    "    \n",
    "    \n",
    "def ingest_data_files(schemas: dict, file_type: list):\n",
    "    # setup db\n",
    "    db_path = Path.cwd().joinpath('testDB.db')\n",
    "    conn = establish_sqlite_db(db_path, schema_dict)\n",
    "    \n",
    "    # collect data files\n",
    "    for tfile in file_type:\n",
    "        data_file_paths = list(Path.cwd().glob(f'**/{tfile}*.csv'))\n",
    "        if not data_file_paths:\n",
    "            continue\n",
    "            \n",
    "        schema = schema_dict.get(tfile)\n",
    "        for data_path in data_file_paths:\n",
    "            line_count = get_line_count(data_path)\n",
    "            rowdata, quarantine = process_data_file(data_path, schema)\n",
    "            print(f\"Starting db load of {data_path.name}: {line_count- 1} records expected\")\n",
    "            load_data_to_db(rowdata, tfile, schema, db_path, conn)     \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec660a-1ead-4308-a4e2-e3966716389e",
   "metadata": {},
   "source": [
    "### Process and load files into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5952f8b-cc4f-4739-b2f8-7384d9765864",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ingest_data_files(schema_dict, file_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91051c-c286-4277-836c-612228a123ee",
   "metadata": {},
   "source": [
    "### Perform analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1647e-2f3c-4367-8532-8d4aa390c99c",
   "metadata": {},
   "source": [
    "#### Question 1. How many patients were enrolled in the program as of July 1st, 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1344bfc-86e0-474a-aa14-02b9e209f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"select count(distinct card_id) from enrollment where enrollment_start_date >= date('2020-07-01');\")\n",
    "cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24863e-30b3-44e7-bbf7-d6c0bd21478d",
   "metadata": {},
   "source": [
    "#### Question 2: how many rows are there in the initial pharmacy claims data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdeb54-e79b-4979-b052-54b2d62803f5",
   "metadata": {},
   "source": [
    "##### This response assumes initial pharmacy claims data set includes all files supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaf0ea-8e4d-49ad-abf3-15e51c6c121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"select count(*) from pharmacy_claims;\")\n",
    "cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ade00-cb3a-4e37-9635-f5e1083f1c70",
   "metadata": {},
   "source": [
    "#### Question 3: How many prepared claims do you have at the end of step 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51245f3f-a689-4424-aea1-330b950e89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "insert_query = \"\"\"\n",
    "insert into analysis\n",
    "WITH paid AS (\n",
    "    SELECT\n",
    "        card_id,\n",
    "        claim_number,\n",
    "        fill_date,\n",
    "        ndc_11,\n",
    "        claim_status,\n",
    "        allowed_amount,\n",
    "        days_supply\n",
    "    FROM\n",
    "        pharmacy_claims\n",
    "    WHERE\n",
    "        claim_status in('PAID')\n",
    "),\n",
    "reversal AS (\n",
    "    SELECT\n",
    "        card_id,\n",
    "        claim_number,\n",
    "        fill_date,\n",
    "        ndc_11,\n",
    "        claim_status,\n",
    "        allowed_amount,\n",
    "        days_supply\n",
    "    FROM\n",
    "        pharmacy_claims\n",
    "    WHERE\n",
    "        claim_status in('REVERSAL')\n",
    "),\n",
    "paid_reversed AS (\n",
    "    SELECT\n",
    "        p.card_id,\n",
    "        p.claim_number,\n",
    "        p.fill_date,\n",
    "        p.ndc_11,\n",
    "        p.claim_status,\n",
    "        r.claim_status AS r_claim_status,\n",
    "        p.days_supply,\n",
    "        r.days_supply AS r_days_supply,\n",
    "        p.days_supply + r.days_supply AS net_days_supply,\n",
    "        p.allowed_amount,\n",
    "        r.allowed_amount AS r_allowed_amount,\n",
    "        p.allowed_amount + r.allowed_amount AS net_allowed_amount\n",
    "    FROM\n",
    "        paid AS p\n",
    "        INNER JOIN reversal r ON p.card_id = r.card_id\n",
    "            AND p.claim_number = r.claim_number\n",
    "            AND p.fill_date = r.fill_date\n",
    "            AND p.ndc_11 = r.ndc_11\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM (\n",
    "    SELECT\n",
    "        ph.card_id,\n",
    "        ph.claim_number,\n",
    "        ph.fill_date,\n",
    "        ph.ndc_11,\n",
    "        ph.claim_status,\n",
    "        ph.days_supply,\n",
    "        ph.allowed_amount\n",
    "    FROM\n",
    "        pharmacy_claims ph\n",
    "WHERE\n",
    "    claim_status <> 'DENIED'\n",
    "EXCEPT\n",
    "SELECT\n",
    "    pr.card_id,\n",
    "    pr.claim_number,\n",
    "    pr.fill_date,\n",
    "    pr.ndc_11,\n",
    "    pr.claim_status,\n",
    "    pr.days_supply,\n",
    "    pr.allowed_amount\n",
    "FROM\n",
    "    paid_reversed AS pr\n",
    "WHERE\n",
    "    claim_status = 'PAID'\n",
    "    AND pr.net_days_supply <= 0\n",
    "EXCEPT\n",
    "SELECT\n",
    "    pr2.card_id,\n",
    "    pr2.claim_number,\n",
    "    pr2.fill_date,\n",
    "    pr2.ndc_11,\n",
    "    pr2.r_claim_status AS claim_status,\n",
    "    pr2.r_days_supply AS days_supply,\n",
    "    pr2.r_allowed_amount AS allowed_amount\n",
    "FROM\n",
    "    paid_reversed AS pr2\n",
    "WHERE\n",
    "    pr2.r_claim_status = 'REVERSAL') AS foo\n",
    "WHERE\n",
    "    foo.days_supply > 0;\n",
    "\"\"\"\n",
    "cur.execute(insert_query)\n",
    "conn.commit()\n",
    "cur.execute('select count(*) from analysis;')\n",
    "cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c8084-7d9b-41e0-92e5-e7cbd99a757b",
   "metadata": {},
   "source": [
    "#### Question 4: What is the highest amount_allowed? Which patient and generic drug does it correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df9f06-1c89-4192-8cd2-b63e23ae68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_dict = get_json_from_file(Path.cwd().joinpath('ndc9_lookup.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21018d4-8dca-4cc3-a0a8-7c1744a90e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_med_query = \"\"\"\n",
    "WITH patient AS (\n",
    "    SELECT\n",
    "        replace(e.card_id,\n",
    "            \"ID\",\n",
    "            \"\") AS card_id,\n",
    "        e.first_name,\n",
    "        e.last_name,\n",
    "        e.gender\n",
    "    FROM\n",
    "        enrollment e\n",
    "    GROUP BY\n",
    "        e.card_id,\n",
    "        e.first_name,\n",
    "        e.last_name,\n",
    "        e.gender\n",
    "),\n",
    "meds AS (\n",
    "    SELECT\n",
    "        card_id,\n",
    "        ndc_11,\n",
    "        sum(days_supply) AS days_supply,\n",
    "        sum(allowed_amount) AS allowed_amount\n",
    "    FROM\n",
    "        analysis\n",
    "    WHERE\n",
    "        fill_date BETWEEN date('2020-01-01')\n",
    "        AND date('2020-06-30')\n",
    "    GROUP BY\n",
    "        card_id,\n",
    "        ndc_11\n",
    ")\n",
    "SELECT\n",
    "    pt.card_id, pt.first_name, pt.last_name, md.ndc_11, md.days_supply, md.allowed_amount\n",
    "FROM\n",
    "    patient pt\n",
    "    JOIN meds md ON pt.card_id = md.card_id;\n",
    "\"\"\"\n",
    "cur = conn.cursor()\n",
    "cur.execute(patient_med_query)\n",
    "pt_med_results = cur.fetchall()\n",
    "\n",
    "highest_allowed = pt_med_results[0]\n",
    "for i in pt_med_results:\n",
    "    if i[5] > highest_allowed[5]:\n",
    "        highest_allowed = i\n",
    "ndc9 = convert_ndc(highest_allowed[3])\n",
    "generic_med = ndc_dict[ndc9]['genericName']\n",
    "print(f'highest allowed_amount: {highest_allowed[5]}')\n",
    "print(f'highest allowed_amount patient: {highest_allowed[1]} {highest_allowed[2]} {generic_med}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047563b2-4b0c-4288-91f5-f539c77bd670",
   "metadata": {},
   "source": [
    "#### Question 5: How many unique generic names for the patient Abe Lincoln?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb7154-074c-40ff-a42f-f46bbe7cba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_summary_query = \"\"\"\n",
    "WITH patient AS (\n",
    "    SELECT DISTINCT\n",
    "        replace(e.card_id,\n",
    "            \"ID\",\n",
    "            \"\") AS card_id,\n",
    "        e.first_name,\n",
    "        e.last_name,\n",
    "        e.gender,\n",
    "        e.enrollment_start_date,\n",
    "        e.enrollment_end_date\n",
    "    FROM\n",
    "        enrollment e\n",
    "    WHERE\n",
    "        enrollment_start_date <= date(\"2020-07-01\")\n",
    "        and(enrollment_end_date = NULL\n",
    "            OR enrollment_end_date > date(\"2020-07-01\"))\n",
    "),\n",
    "meds AS (\n",
    "    SELECT\n",
    "        card_id,\n",
    "        ndc_11,\n",
    "        sum(days_supply) AS days_supply,\n",
    "        sum(allowed_amount) AS allowed_amount\n",
    "    FROM\n",
    "        analysis\n",
    "    WHERE\n",
    "        fill_date BETWEEN date(\"2020-01-01\")\n",
    "        AND date(\"2020-06-30\")\n",
    "    GROUP BY\n",
    "        card_id,\n",
    "        ndc_11\n",
    ")\n",
    "SELECT\n",
    "    pt.card_id,\n",
    "    pt.first_name,\n",
    "    pt.last_name,\n",
    "    md.ndc_11,\n",
    "    md.days_supply,\n",
    "    md.allowed_amount\n",
    "FROM\n",
    "    patient pt\n",
    "    JOIN meds md ON pt.card_id = md.card_id;\n",
    "\"\"\"\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(pt_summary_query)\n",
    "pt_summary_results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6c7f9-4161-4c71-8061-89835023ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a hash table of patients\n",
    "pt_hash = {}\n",
    "template = {\n",
    "    \"first_name\": \"\",\n",
    "    \"last_name\": \"\",\n",
    "    \"med_summary\": {}\n",
    "}\n",
    "\n",
    "med_template = {\n",
    "    \"allowed_amount\": None,\n",
    "    \"days_supply\": None\n",
    "}\n",
    "while pt_summary_results:\n",
    "    card_id = pt_summary_results[0][0]\n",
    "    try:\n",
    "        pt_hash[card_id]\n",
    "    except KeyError:\n",
    "        pt_template = copy.deepcopy(template)\n",
    "        pt_template[\"first_name\"] = pt_summary_results[0][1]\n",
    "        pt_template[\"last_name\"] = pt_summary_results[0][2]\n",
    "        pt_hash[card_id] = pt_template\n",
    "    \n",
    "    ndc9 = convert_ndc(pt_summary_results[0][3])\n",
    "    try:\n",
    "        drug_info = ndc_dict[ndc9]\n",
    "        generic = drug_info['genericName']\n",
    "        \n",
    "        pt_med_template = copy.deepcopy(med_template)\n",
    "        pt_med_template[\"allowed_amount\"] = pt_summary_results[0][5]\n",
    "        pt_med_template[\"days_supply\"] = pt_summary_results[0][4]\n",
    "        pt_hash[card_id][\"med_summary\"][generic] = pt_med_template\n",
    "    except KeyError:\n",
    "        print(f'generic drug not found for ndc: {ndc9}')\n",
    "    pt_summary_results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d001f-6468-4cdb-8eaf-cd0239116443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in pt_hash.keys():\n",
    "    with open(Path.cwd().joinpath(f\"results/patient-ID{key}.json\"), \"w\") as writer:\n",
    "        writer.write(json.dumps(pt_hash[key], indent=4))\n",
    "    \n",
    "    if pt_hash[key][\"first_name\"] == \"Abe\" and pt_hash[key][\"last_name\"] == \"Lincoln\":\n",
    "        print(f\"Abe Lincoln has [ {len(pt_hash[key]['med_summary'].keys())} ] generic medications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b13f41-a3fe-4ed8-bae7-d1b0796ccd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
